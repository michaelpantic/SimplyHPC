@article{BenBelgacem2015,
author = {{Ben Belgacem}, Mohamed and Chopard, Bastien},
doi = {10.1016/j.future.2014.08.003},
file = {:C$\backslash$:/Users/lmirosla/Downloads/1-s2.0-S0167739X14001514-main.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {distributed computation},
mendeley-groups = {Cloud computing},
month = jan,
pages = {11--21},
publisher = {Elsevier B.V.},
title = {{A hybrid HPC/cloud distributed infrastructure: Coupling EC2 cloud resources with HPC clusters to run large tightly coupled multiscale applications}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0167739X14001514},
volume = {42},
year = {2015}
}

@article{HPCG,
author = {Jack Dongarra and Michael A. Heroux},
journal = {Sandia Report},
volume = {SAND2013-4744},
title = {Toward a New Metric for Ranking High Performance Computing Systems},
url = {http://www.sandia.gov/~maherou/docs/HPCG-Benchmark.pdf},
year = {2013}
}

@techreport{Heroux2013,
author = {Heroux, Michael A and Laboratories, Sandia National},
file = {:D$\backslash$:/MicrosoftHPC/Docs/Paper/bibliography/HPCG-Specification.pdf:pdf},
institution = {Sandia National Laboratories},
mendeley-groups = {Cloud computing},
number = {October},
pages = {1--21},
title = {{HPCG Technical Specification}},
url = {https://software.sandia.gov/hpcg/about.php},
year = {2013}
}


@techreport{ansysScaling,
author = {HPC Advisory Board},
mendeley-groups = {Cloud computing},
number = {October},
title = {{ANSYS Performance Benchmark
and Profiling}},
url = {http://www.hpcadvisorycouncil.com/pdf/ANSYS_Performance_Analysis.pdf},
year = {2010}
}

@incollection{Xianyi2014,
abstract = {In this paper, a first attempt has been made on optimizing and scaling HPCG on the world’s largest supercomputer, Tianhe-2. This early work focuses on the optimization of the CPU code without using the Intel Xeon Phi coprocessors. In our work, we reformulate the basic CG algorithm to minimize the cost of collective communication and employ several optimizing techniques such as SIMDization, loop unrolling, forward and backward sweep fusion, OpenMP parallization to further enhance the performance of kernels such as the sparse matrix vector multiplication, the symmetric Gauss–Seidel relaxation and the geometric multigrid v-cycle. We successfully scale the HPCG code from 256 up to 6,144 nodes (147,456 CPU cores) on Tianhe-2, with a nearly ideal weak scalability and an aggregate performance of 79.83 Tflops, which is 6.38X higher than the reference implementation.},
address = {Cham},
annote = {HPC Benchmark on Tianhe-2 cluster.},
author = {Xianyi, Zhang and Chao, Yang and Fangfang, Liu and Yiqun, Liu and Yutong, Lu},
booktitle = {Lecture Notes in Computer Science},
chapter = {Optimizing},
doi = {10.1007/978-3-319-11197-1},
editor = {Sun, Xian-he and Qu, Wenyu and Stojmenovic, Ivan and Zhou, Wanlei and Li, Zhiyang and Guo, Hua and Min, Geyong and Yang, Tingting and Wu, Yulei and Liu, Lei},
isbn = {978-3-319-11196-4},
keywords = {hpcg},
mendeley-groups = {Cloud computing},
mendeley-tags = {hpcg},
pages = {28--41},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Algorithms and Architectures for Parallel Processing}},
url = {http://link.springer.com/10.1007/978-3-319-11197-1},
volume = {8630},
year = {2014}
}

@article{Wong2013,
abstract = {Clouds have provided on-demand, scalable and affordable High Performance Computing (HPC) resources to discipline (e.g., Biology, Medicine, Chemistry) scientists. However, the steep learning curve of preparing a HPC cloud and deploying HPC applications has hindered many scientists to achieve innovative discoveries for which HPC resources must be relied on. With the world moving to web-based tools, scientists are also seeking more web-based technologies to support their research. Unfortunately, the discipline problems of high-performance computational research are both unique and complex, which make the development of web-based tools for this research difficult. This paper presents our work on developing a unified cloud framework that allows discipline users to easily deploy and expose HPC applications in public clouds as services. To provide a proof of concept, we have implemented the cloud framework prototype by integrating three components: (i) Amazon EC2 public cloud for providing HPC infrastructure, (ii) a HPC service software library for accessing HPC resources, and (iii) the Galaxy web-based platform for exposing and accessing HPC application services. This new approach can reduce the time and money needed to deploy, expose and access discipline HPC applications in clouds.},
author = {Wong, Adam K.L. and Goscinski, Andrzej M.},
doi = {10.1016/j.future.2013.01.014},
file = {:C$\backslash$:/Users/lmirosla/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong, Goscinski - 2013 - A unified framework for the deployment, exposure and access of HPC applications as services in clouds.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Application deployment and exposure,HPC application service,High performance computing,SaaS clouds,amazon,platform},
mendeley-groups = {Cloud computing},
mendeley-tags = {amazon,platform},
month = aug,
number = {6},
pages = {1333--1344},
title = {{A unified framework for the deployment, exposure and access of HPC applications as services in clouds}},
url = {http://www.sciencedirect.com/science/article/pii/S0167739X13000307},
volume = {29},
year = {2013}
}

@InProceedings{petsc-efficient,
            Author = "Satish Balay and William D. Gropp and Lois Curfman McInnes and Barry F.  Smith",
            Title = "Efficient Management of Parallelism in Object Oriented Numerical Software Libraries",
            Booktitle = "Modern Software Tools in Scientific Computing",
            Editor = "E. Arge and A. M. Bruaset and H. P. Langtangen",
            Pages = "163--202",
            Publisher = "Birkh{\"{a}}user Press",
            Year = "1997"
}


@Misc{petsc-web-page,
            author = {Satish Balay and Shrirang Abhyankar and Mark~F. Adams and Jed Brown and Peter Brune
                      and Kris Buschelman and Lisandro Dalcin and Victor Eijkhout and William~D. Gropp
                      and Dinesh Kaushik and Matthew~G. Knepley
                      and Lois Curfman McInnes and Karl Rupp and Barry~F. Smith
                      and Stefano Zampini and Hong Zhang},
            title =  {{PETS}c {W}eb page},
            url =    {http://www.mcs.anl.gov/petsc},
            howpublished = {\url{http://www.mcs.anl.gov/petsc}},
            year = {2014}
          }


@inproceedings{Gutknecht2005,
address = {Berlin Heidelberg},
author = {Gutknecht, Martin H},
booktitle = {Proceedings of the International Symposium on Frontiers of Computational Science},
editor = {{Sasai, M. Kaneda, Y. Kawamura}, H.},
file = {:D$\backslash$:/MicrosoftHPC/Docs/Paper/bibliography/Krylov Solvers Brief Introduction.pdf:pdf},
keywords = {iterative solvers},
mendeley-groups = {Numerics},
mendeley-tags = {iterative solvers},
pages = {53--62},
publisher = {Springer-Verlag},
title = {{A Brief Introduction to Krylov Space Methods for Solving Linear Systems}},
url = {http://www.sam.math.ethz.ch/~mhg/pub/biksm.pdf},
year = {2005}
}

@techreport{Perry2007,
author = {Perry, Randy and Gillen, Al},
institution = {IDC},
file = {:D$\backslash$:/MicrosoftHPC/Docs/Paper/bibliography/IDC Whitepaper Demonstrating Business Value.pdf:pdf},
mendeley-groups = {Cloud computing},
title = {{Demonstrating Business Value : Selling to Your C-Level Executives}},
url = {http://download.microsoft.com/download/1/9/2/192e73a4-7abb-4bad-b469-34632d54a8a6/IDC Whitepaper Demonstrating Business Value.pdf},
year = {2007}
}

@book{catlett2013cloud,
  booktitle={Cloud Computing and Big Data},	
	title={A cloud framework for big data analytics Workflows on Azure},
  author={Marozzo Fabrizio, Talia Dominico, Trunfio Paolo},
	eds={Catlett, C. and Gentzsch, W. and Grandinetti, L.},
  isbn={9781614993223},
  series={Advances in Parallel Computing},
  url={http://books.google.ch/books?id=Kgd7AgAAQBAJ},
  year={2013},
  publisher={IOS Press}
}


@book{kaminsky15,
  booktitle={Big CPU, Big Data},	
	title={Solving the World's Toughest Computational Problems with Parallel Computing},
  author={Alan Kaminsky},	    
  url={http://www.cs.rit.edu/~ark/bcbd/},
  year={2015},
  publisher={Creative Commons Attribution}
}

@MISC{Balaji,
    author = {Pavan Balaji and Darius Buntinas and David Goodell and Sameer Kumar Ewing Lusk},
    title = {MPI on a Million Processors},
		publisher = {CiteSeerX},
    year = {}
}

@misc{azure,
url	 = {http://azure.microsoft.com},
title = {Windows azure},
key = {Windows azure},
note = {\url{http://azure.microsoft.com}. Accessed in May 2015.}
}

@misc{ec2,
url	 = {http://aws.amazon.com/ec2/},
title = {Amazon {EC2}},
key = {Amazon EC2},
note = {\url{http://aws.amazon.com/ec2/}. Accessed in May 2015.}
}
 
@misc{google,
url	 = {https://cloud.google.com/},
title = {Google Cloud Platform},
key = {Google Cloud Platform},
note = {URL \url{https://cloud.google.com/}. Accessed in May 2015.}
}

@misc{ubercloud,
author = {Gentzsch, Wolfgang},
booktitle = {The UberCloud},
mendeley-groups = {Cloud computing},
title = {How Cost Efficient is HPC in the Cloud?},
url = {https://www.theubercloud.com/cost/},
urldate = {December 2012}
}

@misc{theuebercloud,
url	 = {https://theuebercloud.com/},
title = {The Uebercloud},
key = {The Uebercloud},
note = {URL \url{https://theuebercloud.com/}. Accessed in May 2015.}
}

@misc{mpiBlas,
url	 = {http://www.mpiblast.org},
title = {MPI BLAS},
key = {MPI BLAS},
note = {URL \url{http://www.mpiblast.org}. Accessed in May 2015.}
}

@misc{OpenStack,
url	 = {http://www.openstack.org},
key = {Open Stack},
title = {Open Stack},
note = {\url{http://www.openstack.org}. Accessed in May 2015.}
}

@misc{CloudStack,
url	 = {http://cloudstack.apache.org},
key = {Cloud Stack},
title = {Cloud Stack},
note = {\url{http://cloudstack.apache.org}. Accessed in May 2015.}
}

@misc{eucalyptus,
url	 = {https://www.eucalyptus.com/},
key = {Eucalyptus},
title = {Eucalyptus},
note = {\url{https://www.eucalyptus.com/}. Accessed in May 2015.}
}

@misc{cloudScores,
url	 = {https://cloudharmony.com/cloudscores},
key = {Cloud Scores},
title = {Cloud Scores},
note = {URL \url{https://cloudharmony.com/cloudscores}. Accessed in May 2015.}
}

@misc{jclouds,
url	 = {https://jclouds.apache.org},
key = {Apache jclouds},
title = {Apache jclouds},
note = {\url{https://jclouds.apache.org}. Accessed in November 2015.}
}

@misc{libcloud,
url	 = {https://libcloud.apache.org},
key = {Apache Libcloud},
title = {Apache Libcloud},
note = {\url{https://libcloud.apache.org}. Accessed in November 2015.}
}

@misc{MPI,
url	 = {http://www.mpi-forum.org},
key = {MPI},
title = {MPI Forum},
note = {URL \url{http://www.mpi-forum.org}. Accessed in June 2015.}
}



@misc{openfoam,
url	 = {http://openfoam.org},
key = {OpenFOAM},
title = {OpenFOAM},
note = {URL \url{http://openfoam.org}. Accessed in May 2015.}
}


@misc{mcae2012,
url	 = {http://www.01consulting.net/02_2011_MCAE_GLOBAL_Market_ES.html},
key = {MCAE},
title = {MCAE Global Market 2011 - Executive Summary},
note = {URL \url{http://www.01consulting.net/02_2011_MCAE_GLOBAL_Market_ES.html}. Accessed in May 2015.}
}

@article{Garg2013,
abstract = {Cloud computing is revolutionizing the IT industry by enabling them to offer access to their infrastructure and application services on a subscription basis. As a result, several enterprises including IBM, Microsoft, Google, and Amazon have started to offer different Cloud services to their customers. Due to the vast diversity in the available Cloud services, from the customer’s point of view, it has become difficult to decide whose services they should use and what is the basis for their selection. Currently, there is no framework that can allow customers to evaluate Cloud offerings and rank them based on their ability to meet the user’s Quality of Service (QoS) requirements. In this work, we propose a framework and a mechanism that measure the quality and prioritize Cloud services. Such a framework can make a significant impact and will create healthy competition among Cloud providers to satisfy their Service Level Agreement (SLA) and improve their QoS. We have shown the applicability of the ranking framework using a case study.},
annote = {Azure evaluated among three cloud providers.},
author = {Garg, Saurabh Kumar and Versteeg, Steve and Buyya, Rajkumar},
doi = {10.1016/j.future.2012.06.006},
file = {::},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,QoS,Quality of service,Service level agreement,Service measurement},
mendeley-groups = {Cloud computing},
mendeley-tags = {QoS},
month = jun,
number = {4},
pages = {1012--1023},
title = {{A framework for ranking of cloud computing services}},
url = {http://www.sciencedirect.com/science/article/pii/S0167739X12001422},
volume = {29},
year = {2013}
}

@inproceedings{Delimitrou:2014:QRQ:2541940.2541941,
 author = {Delimitrou, Christina and Kozyrakis, Christos},
 title = {Quasar: Resource-efficient and QoS-aware Cluster Management},
 booktitle = {Proceedings of the 19th International Conference on Architectural Support for Programming Languages and Operating Systems},
 series = {ASPLOS '14},
 year = {2014},
 isbn = {978-1-4503-2305-5},
 location = {Salt Lake City, Utah, USA},
 pages = {127--144},
 numpages = {18},
 url = {http://doi.acm.org/10.1145/2541940.2541941},
 doi = {10.1145/2541940.2541941},
 acmid = {2541941},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cloud computing, cluster management, datacenters, quality of service, resource allocation and assignment, resource efficiency},
} 

@article{Popinet2003,
abstract = {An adaptive mesh projection method for the time-dependent incompressible Euler equations is presented. The domain is spatially discretised using quad/octrees and a multilevel Poisson solver is used to obtain the pressure. Complex solid boundaries are represented using a volume-of-fluid approach. Second-order convergence in space and time is demonstrated on regular, statically and dynamically refined grids. The quad/octree discretisation proves to be very flexible and allows accurate and efficient tracking of flow features. The source code of the method implementation is freely available.},
annote = {Gerris has been used by theubercloud 
https://www.theubercloud.com/experiments/team-60-unsteady-flow-around-aircraft-landing-gear/},
author = {Popinet, St\'{e}phane},
doi = {10.1016/S0021-9991(03)00298-5},
file = {:C$\backslash$:/Users/lmirosla/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Popinet - 2003 - Gerris a tree-based adaptive solver for the incompressible Euler equations in complex geometries.pdf:pdf},
issn = {00219991},
journal = {Journal of Computational Physics},
keywords = {65M06,65N06,65N55,76-04,76D05,Adaptive mesh refinement,Approximate projection method,Complex geometry,Incompressible flow,cfd},
mendeley-groups = {CFD},
mendeley-tags = {cfd},
month = sep,
number = {2},
pages = {572--600},
title = {{Gerris: a tree-based adaptive solver for the incompressible Euler equations in complex geometries}},
url = {http://www.sciencedirect.com/science/article/pii/S0021999103002985},
volume = {190},
year = {2003}
}

@article{Lu2014,
abstract = {MapReduce as a service enjoys wide adoption in commercial clouds today  [3,23]. But most cloud providers just deploy native Hadoop  [24] systems on their cloud platforms to provide MapReduce services without any adaptation to these virtualized environments  [6,25]. In cloud environments, the basic executing units of data processing are virtual machines. Each user’s virtual cluster needs to deploy HDFS  [26] every time when it is initialized, while the user’s input and output data should be transferred between the HDFS and external persistent data storage to ensure that the native Hadoop works properly. These costly data movements can lead to significant performance degradation of MapReduce jobs in the cloud. We present Morpho—a modified version of the Hadoop MapReduce framework, which decouples storage and computation into physical clusters and virtual clusters respectively. In Morpho, the map/reduce tasks are still running in VMs without corresponding ad-hoc HDFS deployments; instead, HDFS is deployed on the underlying physical machines. When MapReduce computation is performing, the map tasks can get data directly from physical machines without any extra data transfers. We design data location perception module to improve the cooperativity of the computation and storage layers, which means that the map tasks can intelligently fetch information about the network topology of physical machines and the VM placements. Additionally, Morpho also achieves high performance by two complementary strategies for data placement and VM placement, which can provide better map and reduce input locality. Furthermore, our data placement strategy can mitigate the resource contentions between jobs. The evaluation of our Morpho system prototype shows it achieves a nearly 62\% speedup of job execution time and a significant reduction in network traffic of the entire system compared with the traditional cloud computing scheme of Amazon and other cloud providers.},
annote = {Morpho, with its decoupled MapReduce mechanism and complementary data and VM placement, is unique in exploiting MapReduce in cloud computing.},
author = {Lu, Lu and Shi, Xuanhua and Jin, Hai and Wang, Qiuyue and Yuan, Daxing and Wu, Song},
doi = {10.1016/j.future.2013.12.026},
file = {:C$\backslash$:/Users/lmirosla/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lu et al. - 2014 - Morpho A decoupled MapReduce framework for elastic cloud computing.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Cloud computing,Data placement,MapReduce,Virtual machine scheduling},
mendeley-groups = {Cloud computing},
month = jul,
pages = {80--90},
title = {{Morpho: A decoupled MapReduce framework for elastic cloud computing}},
url = {http://www.sciencedirect.com/science/article/pii/S0167739X13002902},
volume = {36},
year = {2014}
}

@article{twister4azure,
abstract = {Recent advances in data-intensive computing for science discovery are fueling a dramatic growth in the use of data-intensive iterative computations. The utility computing model introduced by cloud computing, combined with the rich set of cloud infrastructure and storage services, offers a very attractive environment in which scientists can perform data analytics. The challenges to large-scale distributed computations on cloud environments demand innovative computational frameworks that are specifically tailored for cloud characteristics to easily and effectively harness the power of clouds. Twister4Azure is a distributed decentralized iterative MapReduce runtime for Windows Azure Cloud. Twister4Azure extends the familiar, easy-to-use MapReduce programming model with iterative extensions, enabling a fault-tolerance execution of a wide array of data mining and data analysis applications on the Azure cloud. Twister4Azure utilizes the scalable, distributed and highly available Azure cloud services as the underlying building blocks, and employs a decentralized control architecture that avoids single point failures. Twister4Azure optimizes the iterative computations using a multi-level caching of data, a cache-aware decentralized task scheduling, hybrid tree-based data broadcasting and hybrid intermediate data communication. This paper presents the Twister4Azure iterative MapReduce runtime and a study of four real world data-intensive scientific applications implemented using Twister4Azure–two iterative applications, Multi-Dimensional Scaling and KMeans Clustering; and two pleasingly parallel applications, BLAST+ sequence searching and SmithWaterman sequence alignment. Performance measurements show comparable or a factor of 2 to 4 better results than the traditional MapReduce runtimes deployed on up to 256 instances and for jobs with tens of thousands of tasks. We also study and present solutions to several factors that affect the performance of iterative MapReduce applications on Windows Azure Cloud.},
author = {Gunarathne, Thilina and Zhang, Bingjing and Wu, Tak-Lon and Qiu, Judy},
doi = {10.1016/j.future.2012.05.027},
file = {:C$\backslash$:/Users/lmirosla/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gunarathne et al. - 2013 - Scalable parallel computing on clouds using Twister4Azure iterative MapReduce.pdf:pdf},
issn = {0167739X},
journal = {Future Generation Computer Systems},
keywords = {Azure,Cloud computing,HPC,Iterative MapReduce,Scientific applications,azure},
mendeley-groups = {Cloud computing},
mendeley-tags = {azure},
month = jun,
number = {4},
pages = {1035--1048},
title = {{Scalable parallel computing on clouds using Twister4Azure iterative MapReduce}},
url = {http://www.sciencedirect.com/science/article/pii/S0167739X12001379},
volume = {29},
year = {2013}
}


@article{tomczak2013,
author = { Tadeusz   Tomczak  and  Katarzyna   Zadarnowska  and  Zbigniew   Koza  and  Maciej   Matyka  and  Łukasz   Mirosław },
title = {Acceleration of iterative Navier-Stokes solvers on graphics processing units},
journal = {International Journal of Computational Fluid Dynamics},
volume = {27},
number = {4-5},
pages = {201-209},
year = {2013},
doi = {10.1080/10618562.2013.804178},
URL = { 
        http://dx.doi.org/10.1080/10618562.2013.804178 },
eprint = { 
        http://dx.doi.org/10.1080/10618562.2013.804178 }
}

@article{Che09042015,
author = {Che, Yonggang and Xu, Chuanfu and Fang, Jianbin and Wang, Yongxian and Wang, Zhenghua}, 
title = {Realistic Performance Characterization of CFD Applications on Intel Many Integrated Core Architecture},
year = {2015}, 
doi = {10.1093/comjnl/bxv022}, 
abstract ={This paper studies the performance characteristics of computational fluid dynamics (CFD) applications on Intel Many Integrated Core (MIC) architecture. Three CFD applications, BT-MZ, LM3D and HOSTA, are evaluated on Intel Knights Corner (KNC) coprocessor, the first public MIC product. The results show that the pure OpenMP scalability of these applications is not sufficient to utilize the potential of a KNC coprocessor. While utilizing the hybrid MPI/OpenMP programming model helps to improve the parallel scalability, the maximum parallel speedup relative to a single thread is still not satisfactory. The OpenCL version of BT-MZ performs better than the OpenMP version but is not comparable to the MPI version and the hybrid MPI/OpenMP version. At the micro-architecture level, while the three CFD applications achieve reasonable instruction execution rates and L1 data cache hit rates, use a large percent of vector instructions, they have low arithmetic density, incur very high branch misprediction rates and do not utilize the Vector Processing Unit efficiently. As a result, they achieve very low single thread floating-point efficiency. For these applications to attain competitive performance on the MIC architecture as on the Xeon processors, both the parallel scalability and the single thread performance should be improved, which is a difficult task.}, 
URL = {http://comjnl.oxfordjournals.org/content/early/2015/04/09/comjnl.bxv022.abstract}, 
eprint = {http://comjnl.oxfordjournals.org/content/early/2015/04/09/comjnl.bxv022.full.pdf+html}, 
journal = {The Computer Journal} 
}
